{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom imblearn.under_sampling import NearMiss\nfrom collections import Counter\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":16,"outputs":[{"output_type":"stream","text":"/kaggle/input/fraud-con-balanceo/kernel77fd79df23 (1).ipynb\n/kaggle/input/creditcardfraud/creditcard.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fraud_file='../input/creditcardfraud/creditcard.csv'\nfraud=pd.read_csv(fraud_file)\nfraud.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fraud.groupby(\"Class\").size())","execution_count":3,"outputs":[{"output_type":"stream","text":"Class\n0    284315\n1       492\ndtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"Class\", data=fraud)\nplt.show","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<function matplotlib.pyplot.show(*args, **kw)>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=fraud.Class\ny.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"0    0\n1    0\n2    0\n3    0\n4    0\nName: Class, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=fraud.drop([\"Class\"], axis=1)\nX.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V20       V21       V22       V23       V24  \\\n0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n\n        V25       V26       V27       V28  Amount  \n0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n1  0.167170  0.125895 -0.008983  0.014724    2.69  \n2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n3  0.647376 -0.221929  0.062723  0.061458  123.50  \n4 -0.206010  0.502292  0.219422  0.215153   69.99  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X,test_X,train_y,test_y=train_test_split(X,y, train_size=0.7, random_state=1)\n\nfraud_model=LogisticRegression()\nfraud_model.fit(train_X,train_y)\ntest_predictions=fraud_model.predict(test_X)\nprint(test_predictions)","execution_count":32,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","name":"stderr"},{"output_type":"stream","text":"[0 0 0 ... 0 0 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(test_predictions,test_y))","execution_count":33,"outputs":[{"output_type":"stream","text":"[[85278    55]\n [   30    80]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_predictions,test_y))","execution_count":34,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85333\n           1       0.59      0.73      0.65       110\n\n    accuracy                           1.00     85443\n   macro avg       0.80      0.86      0.83     85443\nweighted avg       1.00      1.00      1.00     85443\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# balanceo datos haciendo subsampling en la muestra mayoritaria\n\nnr=NearMiss(ratio=0.5, n_neighbors=3, random_state=1)\ntrain_X_miss,train_y_miss=nr.fit_sample(train_X,train_y)\n\n#vemos nuestros datos antes y despues de balancear\n\nprint(\"antes{}\".format(Counter(train_y)))\nprint(\"despues{}\".format(Counter(train_y_miss)))\n\n","execution_count":38,"outputs":[{"output_type":"stream","text":"antesCounter({0: 199007, 1: 357})\ndespuesCounter({0: 714, 1: 357})\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_miss,test_X,train_y_miss,test_y=train_test_split(X,y, train_size=0.7, random_state=1)\n\nnew_model=LogisticRegression()\nnew_model.fit(train_X_miss,train_y_miss)\nnew_predictions=new_model.predict(test_X)\n\n","execution_count":44,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'NearMiss' object has no attribute 'predict'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-3a8b1b26966f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnr_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNearMiss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_miss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_miss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnr_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NearMiss' object has no attribute 'predict'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(new_predictions,test_y))\n\n#porque no hay cambios?\n","execution_count":43,"outputs":[{"output_type":"stream","text":"[[85278    55]\n [   30    80]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test1_predictions,test_y))","execution_count":31,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     85333\n           1       0.59      0.73      0.65       110\n\n    accuracy                           1.00     85443\n   macro avg       0.80      0.86      0.83     85443\nweighted avg       1.00      1.00      1.00     85443\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}